{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "49dbab34-3356-4fef-a6b3-d2d7291714cc",
   "metadata": {},
   "source": [
    "### Chihuahua Or Muffin"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49a093e3-3897-4351-8c94-00f52f42d841",
   "metadata": {},
   "source": [
    "#### Import des librairies de travail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c7931203-83da-435b-abc0-b7b2fb5afd36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Représentation graphique\n",
    "import matplotlib.pyplot as plt\n",
    "# Commande pour afficher les plots inline\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ca77733b-0f91-47e1-a78d-71d4967f0f21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pytorch framework deep learning\n",
    "import torch\n",
    "# Extension Torchvision pour la gestion des datasets\n",
    "from torchvision import datasets, models, transforms\n",
    "# nn = Neural Network (définir les couches)\n",
    "import torch.nn as nn\n",
    "# Fonctions special\n",
    "from torch.nn import functional as F\n",
    "# Optimiseurs\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14f8a46d-6e41-459e-bd8f-6176c620dd66",
   "metadata": {},
   "source": [
    "#### Construction du réseau de neurones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "12048bc0-3e62-496a-bf5c-b1999659809b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MySkynet(nn.Module):\n",
    "    \"\"\"\n",
    "    A very basic neural network.\n",
    "    \"\"\"\n",
    "    def __init__(self, input_dim=(3, 224, 224)):\n",
    "        \"\"\"\n",
    "        Constructs a neural network.\n",
    "        \n",
    "        input_dim: a tuple that represents \"channel x height x width\" dimensions of the input\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        # the total number of RGB pixels in an image is the tensor's volume\n",
    "        num_in_features = input_dim[0] * input_dim[1] * input_dim[2]\n",
    "        # input layer\n",
    "        self.layer_0 = nn.Linear(num_in_features, 128)\n",
    "        # hidden layers\n",
    "        self.layer_1 = nn.Linear(128, 64)\n",
    "        self.layer_2= nn.Linear(64, 32)\n",
    "        # output layer, output size of 2 for chihuahua and muffin\n",
    "        self.layer_3= nn.Linear(32, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Define the forward pass through our network.\n",
    "        \"\"\"\n",
    "        batch_size = x.shape[0]\n",
    "        # convert our RGB tensor into one long vector\n",
    "        x = x.view(batch_size, -1)\n",
    "        \n",
    "        # pass through our layers\n",
    "        x = F.relu(self.layer_0(x))\n",
    "        x = F.relu(self.layer_1(x))\n",
    "        x = F.relu(self.layer_2(x))\n",
    "        x = F.relu(self.layer_3(x))\n",
    "        \n",
    "        # convert the raw output to probability predictions\n",
    "        x = F.softmax(x, dim=1)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a68f5e1b-f77f-46e8-accf-059958fc4a4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MySkynet(\n",
       "  (layer_0): Linear(in_features=150528, out_features=128, bias=True)\n",
       "  (layer_1): Linear(in_features=128, out_features=64, bias=True)\n",
       "  (layer_2): Linear(in_features=64, out_features=32, bias=True)\n",
       "  (layer_3): Linear(in_features=32, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cuda:0 signifie le premier trouvé\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\") \n",
    "model = MySkynet().to(device)                      \n",
    "# load our simple neural network\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deec1de1-c26f-422b-9140-42f5546349e2",
   "metadata": {},
   "source": [
    "#### Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9278d77b-f9cb-4b46-8a93-7fbf1a971968",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "print(\"Data contents:\", os.listdir(\"data\"))\n",
    "print(\"Train contents:\", os.listdir(\"data/train\"))\n",
    "print(\"Validation contents:\", os.listdir(\"data/validation\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7659cd65-f5d4-46b5-9ddd-bbf453aac472",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image  # import our image opening tool\n",
    "\n",
    "_, ax = plt.subplots(1, 4, figsize=(15,60))  \n",
    "# to show 4 images side by side, make a \"1 row x 4 column\" axes\n",
    "ax[0].imshow(Image.open(\"data/train/chihuahua/4.jpg\"))\n",
    "ax[1].imshow(Image.open(\"data/train/chihuahua/5.jpg\"))\n",
    "ax[2].imshow(Image.open(\"data/train/muffin/131.jpg\"))\n",
    "ax[3].imshow(Image.open(\"data/train/muffin/107.jpg\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5bd0c33-8bd0-4d4e-8226-c8cff9384de6",
   "metadata": {},
   "outputs": [],
   "source": [
    "normalize = transforms.Normalize(mean=[0.5, 0.5, 0.5],\n",
    "                                 std=[0.5, 0.5, 0.5])\n",
    "\n",
    "# transforms for our training data\n",
    "train_transforms = transforms.Compose([\n",
    "    # resize to resnet input size\n",
    "    transforms.Resize((224,224)),\n",
    "    # transform image to PyTorch tensor object\n",
    "    transforms.ToTensor(),\n",
    "    normalize\n",
    "])\n",
    "\n",
    "# these validation transforms are exactly the same as our train transforms\n",
    "validation_transforms = transforms.Compose([\n",
    "    transforms.Resize((224,224)),\n",
    "    transforms.ToTensor(),\n",
    "    normalize\n",
    "])\n",
    "\n",
    "print(\"Train transforms:\", train_transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70957d50-3eef-4039-9d2e-27474486e2d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_datasets = {\n",
    "    'train':\n",
    "        datasets.ImageFolder('data/train', train_transforms),\n",
    "    'validation':\n",
    "        datasets.ImageFolder('data/validation', validation_transforms)}\n",
    "\n",
    "print(\"==Train Dataset==\\n\", image_datasets[\"train\"])\n",
    "print()\n",
    "print(\"==Validation Dataset==\\n\", image_datasets[\"train\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5c289fd-c45f-47f4-97cc-6d611cae199d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloaders = {\n",
    "    'train':\n",
    "        torch.utils.data.DataLoader(\n",
    "            image_datasets['train'],\n",
    "            batch_size=8,\n",
    "            shuffle=True,\n",
    "            num_workers=4),\n",
    "    'validation':\n",
    "        torch.utils.data.DataLoader(\n",
    "            image_datasets['validation'],\n",
    "            batch_size=8,\n",
    "            shuffle=False,\n",
    "            num_workers=4)}\n",
    "\n",
    "print(\"Train loader:\", dataloaders[\"train\"])\n",
    "print(\"Validation loader:\", dataloaders[\"validation\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "113e648a-a679-43b4-a376-03324429b78f",
   "metadata": {},
   "source": [
    "#### Entrainer le modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f79fabf4-fe9b-4b44-ac5d-ef7172bdbea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tnrange, tqdm_notebook # import progress bars to show train progress\n",
    "\n",
    "def train_model(model, dataloaders, loss_function, optimizer, num_epochs):\n",
    "    \"\"\"\n",
    "    Trains a model using the given loss function and optimizer, for a certain number of epochs.\n",
    "    \n",
    "    model: a PyTorch neural network\n",
    "    loss_function: a mathematical function that compares predictions and labels to return an error\n",
    "    num_epochs: the number of times to run through the full training dataset\n",
    "    \"\"\"\n",
    "    # train for n epochs. an epoch is a full iteration through our dataset\n",
    "    for epoch in tnrange(num_epochs, desc=\"Total progress\", unit=\"epoch\"):\n",
    "        # print a header\n",
    "        print('Epoch {}/{}'.format(epoch+1, num_epochs))\n",
    "        print('----------------')\n",
    "\n",
    "        # first train over the dataset and update weights; at the end, calculate our validation performance\n",
    "        for phase in ['train', 'validation']:\n",
    "            if phase == 'train':\n",
    "                model.train()\n",
    "            else:\n",
    "                model.eval() \n",
    "\n",
    "            # keep track of the overall loss and accuracy for this batch\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "             # iterate through the inputs and labels in our dataloader\n",
    "            # (the tqdm_notebook part is to display a progress bar)\n",
    "            for inputs, labels in tqdm_notebook(dataloaders[phase], desc=phase, unit=\"batch\", leave=False):\n",
    "                # move inputs and labels to appropriate device (GPU or CPU)\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                # FORWARD PASS\n",
    "                outputs = model(inputs)\n",
    "                # compute the error of the model's predictions\n",
    "                loss = loss_function(outputs, labels)\n",
    "\n",
    "                if phase == 'train':\n",
    "                    # BACKWARD PASS\n",
    "                    optimizer.zero_grad()  # clear the previous gradients\n",
    "                    loss.backward()        # backpropagate the current error gradients\n",
    "                    optimizer.step()       # update the weights (i.e. do the learning)\n",
    "\n",
    "                # track our accumulated loss\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                # track number of correct to compute accuracy\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "                \n",
    "                # print our progress\n",
    "            epoch_loss = running_loss / len(image_datasets[phase])\n",
    "            epoch_acc = running_corrects.double() / len(image_datasets[phase])\n",
    "            print(f'{phase} error: {epoch_loss:.4f}, Accuracy: {epoch_acc:.4f}')\n",
    "\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e1c18b5-c6bb-4420-8d4a-7bf4f928cb11",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_function = nn.CrossEntropyLoss()              \n",
    "# the most common error function in deep learning\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.1)  \n",
    "# Stochastic Gradient Descent, with a learning rate of 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "426474d6-0140-4fb3-8be2-bcdc5ecbd99f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_model(model, dataloaders, loss_function, optimizer, num_epochs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93c26558-a1d9-43fc-8f1f-373674fe588f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "from math import floor\n",
    "\n",
    "# get all the images from our validation sets\n",
    "validation_img_paths = glob(\"data/validation/**/*.jpg\", recursive=True)\n",
    "images = [Image.open(img_path) for img_path in validation_img_paths]\n",
    "\n",
    "# put all the images together to run through our model\n",
    "validation_batch = torch.stack( [validation_transforms(img).to(device) for img in images])\n",
    "pred_logits_tensor = model(validation_batch)\n",
    "pred_probs = pred_logits_tensor.cpu().data.numpy()\n",
    "\n",
    "# show the probabilities for each picture\n",
    "fig, axs = plt.subplots(6, 5, figsize=(20, 20))\n",
    "for i, img in enumerate(images):\n",
    "    ax = axs[floor(i/5)][i % 5]\n",
    "    ax.axis('off')\n",
    "    ax.set_title(\"{:.0f}% Chi, {:.0f}% Muff\".format(100*pred_probs[i,0], 100*pred_probs[i,1]), fontsize=18)\n",
    "    ax.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a793744-0bc2-461d-93f1-2c82979c83ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "651b803a-2a18-4a82-a33c-430c70753af4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
